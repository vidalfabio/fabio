{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Direcciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3_folder = (path/'train'/'3').ls() # dirección de las imágenes\n",
    "train7_folder = (path/'train'/'7').ls()\n",
    "valid3_folder = (path/'valid'/'3').ls()\n",
    "valid7_folder = (path/'valid'/'7').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creación de los tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(folder):\n",
    "    x = torch.stack([tensor(Image.open(o)) for o in (folder)]).float()/255 # crea una lista con las imágenes (puedo abrir cualquiera con show_image(train_7[])). Divie por 255 para que los valores estén entre 0 y 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_7 = stack(train7_folder) # tensor de rango-3 (6265 matrices de 28x28, siendo cada matriz una imagen)\n",
    "train_3 = stack(train3_folder) # train_3.shape -> torch.Size([6265, 28, 28]) Se tienen así dos sets de entrenamiento, uno para el 3 y otro para el 7\n",
    "valid_3 = stack(valid3_folder) # valid_3.shape -> torch.Size([1010, 28, 28])\n",
    "valid_7 = stack(valid7_folder) # valid_7.shape -> torch.Size([1028, 28, 28]) Se tienen así dos sets de validación, uno para el 3 y otro para el 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([train_3, train_7]).view(-1, 28*28) # concatena los tensores tridimensionales de entrenamiento, y los convierte en una lista de vectores. Las matrices de 28x28 ahora son vectores de largo 28x28=784\n",
    "train_y = tensor([1]*len(train3_folder) + [0]*len(train7_folder)).unsqueeze(1) # crea un vector con tantos 1 como elementos hay en la train3_folder, y tantos 0 como elementos hay en train7_folder\n",
    "\n",
    "valid_x = torch.cat([valid_3, valid_7]).view(-1, 28*28) # el set de validación se muestra también como una colección de vectores\n",
    "valid_y = tensor([1]*len(valid3_folder) + [0]*len(valid7_folder)).unsqueeze(1) # básicamente, el vector de labels para valid_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creación de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y)) # genera un arreglo de tuplas (train_x,train_y) --es un arreglo donde cada vector tiene su correspondiente etiqueta--\n",
    "dset_valid = list(zip(valid_x, valid_y)) # idem para el set de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOpt: # Mediante el atributo Self, se puede acceder a los atributos y métodos de la clase en Python.\n",
    "    def __init__(self, params, lr):\n",
    "        self.params, self.lr = list(params), lr\n",
    "        \n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * self.lr\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, target):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(target ==1, 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, target):\n",
    "    preds= preds.sigmoid()\n",
    "    return ((preds-target)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=56) # crea lotes de elementos, para procesar en paralelo\n",
    "dl_valid = DataLoader(dset_valid, batch_size=56) # idem, con el set de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(x, y, model):\n",
    "    preds = linear1(x)\n",
    "    loss = mnist_loss(preds, y) # calcula el loss para las predicciones respecto a sus labels\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred, target):\n",
    "    return (pred.sigmoid().round().unsqueeze(1) == target).float().mean() # consultar bien esta línea\n",
    "\n",
    "# pred es la predicción hecha con linear1\n",
    "# sigmoid() limita los valores entre 0 y 1\n",
    "# round() los redondea a enteros\n",
    "# unsqueeze(1) le da la misma forma que target, para poder comparar\n",
    "# la comparación da en valores booleanos\n",
    "# .float() los convierte en números\n",
    "# .mean() saca el promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar de ejemplo lo anterior, se puede probar:<br>\n",
    "batch_x = list(dl)[43][0]<br>\n",
    "batch_y = list(dl)[43][1]<br>\n",
    "pred = linear1(batch_x)<br>\n",
    "pred<br>\n",
    "pred.sigmoid()<br>\n",
    "pred.sigmoid().round()<br>\n",
    "(pred.sigmoid().round().unsqueeze(1)<br>\n",
    "(pred.sigmoid().round().unsqueeze(1) == batch_y)<br>\n",
    "(pred.sigmoid().round().unsqueeze(1) == batch_y).float()<br>\n",
    "(pred.sigmoid().round().unsqueeze(1) == batch_y).float().mean()<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "optimizer = BasicOpt(linear1.parameters(),lr)\n",
    "\n",
    "def train_epoch(model):\n",
    "    for x, y in dl: # 'x' sería un lote de entrenamiento, 'y' sus labels\n",
    "        calc_grad(x, y, linear1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accurates = [metric(linear1(x), y) for x,y in dl_valid] # cuenta los aciertos para cada lote\n",
    "    return round(torch.stack(accurates).mean().item(), 4) # hace un vector con los valores, y calcular el promedio. El 4 es la cantidad de decimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6106\n",
      "0.7182\n",
      "0.8215\n",
      "0.8712\n",
      "0.8958\n",
      "0.9103\n",
      "0.9219\n",
      "0.9301\n",
      "0.9407\n",
      "0.9436\n",
      "0.9499\n",
      "0.9533\n",
      "0.9552\n",
      "0.9586\n",
      "0.96\n",
      "0.9619\n",
      "0.9629\n",
      "0.9634\n",
      "0.9658\n",
      "0.9673\n"
     ]
    }
   ],
   "source": [
    "train_model(linear1,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSULTAR BIEN CÓMO SE INICIALIZAN LOS PARÁMETROS, SI NUNCA LLAMÉ A OPT_INIT. ES NECESARIO INICIALIZAR MANUALMENTE UN LEARNING RATE, PERO LOS DEMÁS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(linear1.parameters(),lr) # SGD hace lo mismo que Optimizer, pero viene con fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, dl_valid) # dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, linear1, opt_func=SGD, loss_func=mnist_loss, metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.046402</td>\n",
       "      <td>0.953946</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.045961</td>\n",
       "      <td>0.953946</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.045140</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.044955</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.044777</td>\n",
       "      <td>0.957872</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.044581</td>\n",
       "      <td>0.957872</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.044294</td>\n",
       "      <td>0.957381</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.043876</td>\n",
       "      <td>0.957872</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.957872</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.042730</td>\n",
       "      <td>0.957872</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.958363</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.041524</td>\n",
       "      <td>0.958363</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.041023</td>\n",
       "      <td>0.958853</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.959835</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.959835</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.960325</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.039577</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.039277</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.038993</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.038723</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.038464</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.037971</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.037730</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.037249</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.037006</td>\n",
       "      <td>0.961307</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>0.961797</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.961797</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.962288</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>0.962779</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.035748</td>\n",
       "      <td>0.962779</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.035491</td>\n",
       "      <td>0.963269</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.035234</td>\n",
       "      <td>0.963760</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.034977</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.034720</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.034464</td>\n",
       "      <td>0.964741</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.965232</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.033958</td>\n",
       "      <td>0.966213</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.966213</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.033460</td>\n",
       "      <td>0.966213</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.033214</td>\n",
       "      <td>0.965723</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.966213</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.032729</td>\n",
       "      <td>0.966704</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.966704</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.966704</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.966704</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.031768</td>\n",
       "      <td>0.966704</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(50, lr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0):\n",
    "    return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net1(x):\n",
    "    res = x@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = x@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params(28*28,54)\n",
    "b1 = init_params(54)\n",
    "w2 = init_params((54,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net2 = nn.Sequential(\n",
    "    nn.Linear(28*28,54),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(54,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>0.979462</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.019252</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.018332</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.018229</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.017973</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.017617</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.980443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.017255</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.017151</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.981915</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.016923</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.981915</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.981915</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.016563</td>\n",
       "      <td>0.982406</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, simple_net1, opt_func=SGD, loss_func=mnist_loss, metrics=metric)\n",
    "#learn.fit(40)\n",
    "\n",
    "learn = Learner(dls, simple_net2, opt_func=SGD, loss_func=mnist_loss, metrics=metric)\n",
    "learn.fit(40,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
